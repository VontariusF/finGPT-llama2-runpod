{
  "name": "FinGPT-13B-vLLM",
  "description": "LLaMA2-13B FinGPT sentiment model on Runpod Serverless vLLM",
  "type": "serverless",
  "runsOn": "GPU",
  "gpuCount": 1,
  "gpuTypeId": "NVIDIA A10G",
  "containerDiskInGb": 20,
  "allowedRegions": [],
  "allowedCudaVersions": ["12.1", "12.2", "12.3"],
  "imageName": "runpod/worker-v1-vllm:v2.2.0stable-cuda12.1.0",
  "env": [
    {
      "key": "MODEL_NAME",
      "value": "sgzsh269/fingpt-sentiment_llama2-13b_merged",
      "description": "Hugging Face model ID for the FinGPT LLaMA2-13B model"
    },
    {
      "key": "HF_TOKEN",
      "value": "",
      "description": "Hugging Face access token for gated model download (leave blank to provide at deploy time)"
    },
    {
      "key": "MAX_MODEL_LEN",
      "value": "4096",
      "description": "Maximum context length for the model (tokens)"
    },
    {
      "key": "GPU_MEMORY_UTILIZATION",
      "value": "0.95",
      "description": "Fraction of GPU VRAM to allocate for the model (e.g. 0.95 for 95% usage)"
    },
    {
      "key": "DTYPE",
      "value": "float16",
      "description": "Data type for model weights (float16 for memory efficiency)"
    }
  ]
}
