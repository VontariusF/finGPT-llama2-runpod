# .env.example - Copy to .env and fill in your settings

# Hugging Face token (only needed if the model is gated)
HF_TOKEN=

# Model download URL (GGUF)
MODEL_URL=https://huggingface.co/second-state/FinGPT-MT-Llama-3-8B-LoRA-GGUF/resolve/main/FinGPT-MT-Llama-3-8B-LoRA-Q4_K_M.gguf

# Override defaults if desired
MODEL_FILENAME=FinGPT-MT-Llama3-Q4_K_M.gguf
CONTEXT_LENGTH=4096
MODEL_NAME=fingpt-mt-llama3-8b-lora-gguf

# Client-side (for calling your Runpod endpoint from local scripts)
RUNPOD_API_KEY=
ENDPOINT_ID=
